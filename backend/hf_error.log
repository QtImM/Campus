Starting HKCampus AI... Loading model naver-clova-ix/donut-base-finetuned-cord-v2
Traceback (most recent call last):
  File "D:\工作软件\lib\site-packages\transformers\tokenization_utils_base.py", line 2447, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "D:\工作软件\lib\site-packages\transformers\models\xlm_roberta\tokenization_xlm_roberta_fast.py", line 108, in __init__
    super().__init__(
  File "D:\工作软件\lib\site-packages\transformers\tokenization_utils_fast.py", line 133, in __init__
    fast_tokenizer = convert_slow_tokenizer(slow_tokenizer)
  File "D:\工作软件\lib\site-packages\transformers\convert_slow_tokenizer.py", line 1628, in convert_slow_tokenizer
    return converter_class(transformer_tokenizer).converted()
  File "D:\工作软件\lib\site-packages\transformers\convert_slow_tokenizer.py", line 548, in __init__
    requires_backends(self, "protobuf")
  File "D:\工作软件\lib\site-packages\transformers\utils\import_utils.py", line 1639, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
XLMRobertaConverter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "backend/main.py", line 24, in <module>
    processor = DonutProcessor.from_pretrained(MODEL_NAME)
  File "D:\工作软件\lib\site-packages\transformers\processing_utils.py", line 944, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "D:\工作软件\lib\site-packages\transformers\processing_utils.py", line 990, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "D:\工作软件\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 920, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "D:\工作软件\lib\site-packages\transformers\tokenization_utils_base.py", line 2213, in from_pretrained
    return cls._from_pretrained(
  File "D:\工作软件\lib\site-packages\transformers\tokenization_utils_base.py", line 2448, in _from_pretrained
    except import_protobuf_decode_error():
  File "D:\工作软件\lib\site-packages\transformers\tokenization_utils_base.py", line 87, in import_protobuf_decode_error
    raise ImportError(PROTOBUF_IMPORT_ERROR.format(error_message))
ImportError: 
 requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

